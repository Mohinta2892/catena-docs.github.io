{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"CATENA Documentation","text":"Talk to us: Discord <p>Welcome to CATENA: an end-to-end, developer-friendly pipeline for large-scale connectomics. If you are curious why do we call it CATENA, read here.</p> <p>Use the sidebar to browse each module. If you're new, start with Getting Started.</p> <p>Note: CATENA brings together neuron segmentation (LSDs), synapse detection (Synful), microtubule tracking, neurotransmitter classification, mitochondria segmentation, EM masking, and visualization tools.</p>"},{"location":"getting-started/","title":"Getting Started","text":""},{"location":"getting-started/#install","title":"Install","text":"<ul> <li>Clone the repo</li> <li>Create the relevant conda env or use the Docker for the module you want to run</li> <li>See each module's Overview page for exact steps</li> </ul>"},{"location":"getting-started/#modules","title":"Modules","text":"<ul> <li>Local Shape Descriptors (Neuron Segmentation)</li> <li>Synapse Detection<ul> <li>Synful</li> <li>SimpSyn</li> </ul> </li> <li>EM Mask Generation</li> <li>Mitochondria Segmentation</li> <li>Neurotransmitter Classification</li> <li>Proofreading</li> <li>Visualization (Napari, Neuroglancer)</li> </ul>"},{"location":"why_name_it_catena/","title":"The story behind the name CATENA","text":"<p>Firstly, I should clarify that CATENA is not an acronym. So CATENA can be written as Catena or catena.</p> <p>The story behind naming this package is actually very simple and maybe a little silly.</p> <p>When I ventured into connectomics after two years of working on Magnetic Resonance Imaging at the Queen Square Institute of Neurology, UCL, UK, I was quite stunned by the fragmented software ecosystem in the connectomics world. There were so many good tools, algorithms, and packages, but most were niche. However, a connectome, to me, meant not only that the core neurons and synapses were identified so that a connectivity matrix or a graph could be built, but also that we had other features identified such as cell-types, neurotransmitters at synaptic locations, and even mitochondria.</p> <p>Existing software did all of these things, but never under one umbrella. Different groups optimized different parts, which meant that one had to first find which was the best model to do a given task and then learn its software dependencies. A common problem was also that many of these software packages were old and unmaintained; what you may have read in the paper could no longer be reproduced in code.</p> <p>All of this led me to believe that I could create a package that, while very much standing on the shoulders of giants, gives users (connectome mappers) a one-stop link where they can explore different aspects of both mapping a core connectome and enriching the same connectome with further information. I wanted to bind or <code>chain</code> the popular tools (and even invent a few of my own) under one hood that I would later call Catena. </p> <p>Catena also literally means a chain of connected ideas or objects.</p>"},{"location":"modules/em-mask-generation/","title":"Em Mask Generation","text":"<p>Short overview of what this module does and links to usage.</p> <ul> <li>Install &amp; Usage: See the module's README and scripts.</li> <li>Design Choices: See Design Choices for the \"why\" behind the \"what\".</li> </ul>"},{"location":"modules/em-mask-generation/design-choices/","title":"Design Choices","text":"<p>This page explains the decisions we made, alternatives considered, trade-offs, and future work.</p>"},{"location":"modules/em-mask-generation/design-choices/#problem-goal","title":"Problem / Goal","text":"<p>What outcome are we optimizing for?</p>"},{"location":"modules/em-mask-generation/design-choices/#alternatives-considered","title":"Alternatives Considered","text":"<ul> <li>Option A \u2013 pros/cons</li> <li>Option B \u2013 pros/cons</li> <li>Option C \u2013 pros/cons</li> </ul>"},{"location":"modules/em-mask-generation/design-choices/#decision","title":"Decision","text":"<p>What we chose and why.</p>"},{"location":"modules/em-mask-generation/design-choices/#trade-offs","title":"Trade-offs","text":"<p>Compute, memory, DX, accuracy, portability, etc.</p>"},{"location":"modules/em-mask-generation/design-choices/#implementation-notes","title":"Implementation Notes","text":"<p>Key parameters, scripts, data flow.</p>"},{"location":"modules/em-mask-generation/design-choices/#operational-guidance","title":"Operational Guidance","text":"<p>Tuning tips, failure modes, troubleshooting.</p>"},{"location":"modules/em-mask-generation/design-choices/#future-work-open-questions","title":"Future Work / Open Questions","text":"<p>What we plan to revisit and why.</p>"},{"location":"modules/local-shape-descriptors/","title":"Local Shape Descriptors","text":"<p>Short overview of what this module does and links to usage.</p> <ul> <li>Install &amp; Usage: Please follow module's README and scripts in GitHub for most up-to-date documentation.</li> <li>Design Choices: See Design Choices for the \"why\" behind the \"what\".</li> </ul> <p>Note Our automated methods for connectome mapping will use Electron Microscopy (EM) datasets.</p>"},{"location":"modules/local-shape-descriptors/#what-is-neuron-segmentation","title":"What is neuron segmentation?","text":"<p>In connectomics -- the art of mapping neural wiring diagrams --  we want to trace every neuron throughout a dataset (here Electron Microscopy images or volumes of real brains). These neurons are long, wiggly structures that snake across regions, branch, loop back, and find their friends (other neurons) to make synaptic connections.</p> <p>Traditionally, people did this by hand using CATMAID-like toolkits (The Collaborative Annotation Toolkit for Massive Amounts of Image Data). This is slow, exhausting, and extremely hard to scale to modern datasets that can span terabytes to petabytes. Neuron segmentation is about automating this tracing process so we can reliably reconstruct whole connectomes without an army of human annotators.</p>"},{"location":"modules/local-shape-descriptors/#what-are-local-shape-descriptors","title":"What are Local Shape Descriptors?","text":"<p>Local Shape Descriptors (LSDs) introduce an auxiliary learning task aimed at improving neuron segmentation within electron microscopy volumes. These descriptors are employed alongside conventional voxel-wise direct neighbor affinities to enhance neuron boundary detection. By capturing key local statistics of neurons, such as diameter, elongation, and direction, LSDs significantly refine segmentation accuracy. Comparative studies across a variety of specimens, imaging techniques, and resolutions reveal that incorporating LSDs consistently elevates the performance of affinity-based segmentation methods. This approach not only matches the effectiveness of current state-of-the-art neuron segmentation techniques but also offers a leap in computational efficiency, making it indispensable for processing the extensive datasets expected in future connectomics research.</p> <ul> <li>Read the paper here: Sheridan et al., Nature Methods, 2023</li> <li>Read the original LSD blogpost here</li> </ul> <p>LSDs architecture at a glance (multi-task U-Net) </p> <p> </p> <p>Note These are supervised ML models, hence you need ground truth. Primary tests reveal 40 cubic microns of densely segmented volumes is good to begin with.</p>"},{"location":"modules/local-shape-descriptors/#getting-started","title":"Getting started","text":"<p>Read these:</p> <ul> <li>System Requirements</li> <li>Installation instructions: Docker, Conda</li> <li>Dataset preparation</li> </ul>"},{"location":"modules/local-shape-descriptors/#usage-instructions","title":"Usage instructions","text":"<p>IMPORTANT If you want to only run inference with pretrained model, follow steps.</p>"},{"location":"modules/local-shape-descriptors/#semantic-segmentation-to-get-the-affinity-maps","title":"Semantic Segmentation to get the affinity maps","text":"1. Understand and modify as needed the config.py  For training models   `config.py` contains `SYSTEM`, `DATA`, `PREPROCESS`, `TRAIN`, `MODEL_ISO` (for isotropic datesets) and `MODEL_ANISO` (for anisotropic datasets). Most of these configurations and hyper-parameters have been populated with default used during experiments. You may want to modify them to suit your needs. Please look at the commented text adjacent to the hyper-params set to get an idea of what they are.  Separate `config.py` files for public datasets like CREMI, SNEMI, ZEBRAFINCH are provided.   For running inference with trained models   `config_predict.py` should be used to run affinity prediction. All configurations set in the file should be automatically picked up by `predicter.py` or `super_predicter_daisy.py`. Ensure you set the same architectural hyper-parameters under `MODEL_ISO` OR `MODEL_ANISO` for pytorch to load the weights correctly. Also, ensure you put the data in the correct path inside a `test` folder, and pass the correct `model checkpoint`.   2. Train models with trainer.py  For training models    Set the hyper-params in the `config.py` file and then run:  <pre><code>python trainer.py -c config_cremi.py\n</code></pre>  Note: When a config file is not passed, the default is `config.py`.   3.1 Run affinity predictions as a single process with predicter.py   You can place as many datasets in the `test` folder of your `BRAIN_VOLUME` as you want. Each will be processed but sequentially.  Download **pretrained** models from [here](https://www.dropbox.com/scl/fo/uxmoj3v6i8mos6lwjjvio/h?rlkey=w10iia8rd8alkx3i67u88w0er&amp;dl=0). These models have mostly been trained with default architectural params. We will share more details sooner.  Please modify `config_predict.py` to match your `config.py` used during training. Check **above** for details.   Run prediction  <pre><code>python predicter.py\n</code></pre>  Note: `predicter.py` does not accept a `config.py` args yet! Hence, all changes must be made in `config_predict.py` as this is default.   3.2 Run affinity predictions blockwise multiprocessing with super_predicter_daisy.py  &gt; **WARNING**  &gt; THIS HAS ONLY BEEN TESTED WITH 3D VOLUMES AND USE `SBATCH` FOR SLURM TO SPAWN ACROSS MULTIPLE CARDS AND A VERY LARGE DATASET. &gt; YOU CAN CHANGE IT TO A LOCAL `SUBPROCESS` RUN. WE WILL ALLOW A `ARGS` INPUT FOR THIS SOON.  You can place as many datasets in the `test` folder of your `BRAIN_VOLUME` as you want. Each will be processed but sequentially USING MULTIPLE-WORKERS, which makes the predictions faster.  Download **pretrained** models from [here](https://www.dropbox.com/scl/fo/uxmoj3v6i8mos6lwjjvio/h?rlkey=w10iia8rd8alkx3i67u88w0er&amp;dl=0). These models have mostly been trained with default architectural params. We will share more details sooner.  Please modify `config_predict.py` to match your `config.py` used during training. Check **above** for details.   Run prediction parallely with Daisy task scheduling  <pre><code>python super_predicter_daisy.py -c config/config_predict_{brain_volume}.py\n</code></pre>  Run `super_predicter_daisy_chunkskipping.py` to skip boundary blocks if they don't need to be segmented  <pre><code>python super_predicter_daisy_chunkskipping.py -c config/config_predict_{brain_volume}.py\n</code></pre>"},{"location":"modules/local-shape-descriptors/#instance-segmentation-from-predicted-affinities","title":"Instance Segmentation from predicted affinities","text":"<p>IMPORTANT Output segmentations are saved in the same output zarr under <code>lsd_outputs</code> containing <code>volumes/pred_affs</code>. Agglomeration thresholds are appended to dataset names: <code>volumes/segmentation_055</code></p> 4.1 Extract supervoxels and agglomerate for small ROIs with instance_segmenter.py  &gt; **WARNING**  &gt; This script should be used with volumes that fit into memory. Predicted affinities are cast as before watershedding float32, so you should have enough RAM.  You must keep the output affinities under `lsd_outputs` for `instance_segmenter.py` to pick them up. Edit data paths in `config_predict.py`. Watershed and agglomeration will be run sequentially on all output *zarr* files that contain `volumes/pred_affs`.   Run watershed and agglomeration  <pre><code>python instance_segmenter.py\n</code></pre> 4.2 Extract supervoxels chunk-wise from large volumes with 02_extract_fragments_blockwise.py  &gt; **IMPORTANT**  &gt; Install [MongoDB](https://www.mongodb.com/docs/manual/installation/) before you begin.  &gt; Ensure you have `pymongo~=4.3.3` and `daisy~=1.0`  &gt; **WARNING**  &gt; `db_host = \"localhost:27017\"` and `db_name = \"lsd_parallel_fragments\"` are hardcoded as these in the script. Yet to be supported via `config_predict.py`. `collection_name` would be auto set to the name of your zarr file.   Run watershed with daisy chunk-wise <pre><code>python 02_extract_fragments_blockwise.py\n</code></pre> **NB: 02_extract_fragments_blockwise.py calls [02_extract_fragments_worker.py](engine/post/02_extract_fragments_worker.py)**   5. Agglomerate supervoxels of large volumes chunk-wise with 03_agglomerate_blockwise.py  &gt; **WARNING**  &gt; This cannot be run if `02_extract_fragments_blockwise.py` has not been run.   Run agglomeration with daisy chunk-wise <pre><code>python 03_agglomerate_blockwise.py\n</code></pre> **NB: 03_agglomerate_blockwise.py calls [03_agglomerate_worker.py](engine/post/03_agglomerate_worker.py)**"},{"location":"modules/local-shape-descriptors/#final-steps-to-extract-final-segmentation-for-large-volumes","title":"Final steps to extract final segmentation for LARGE volumes","text":"6. Finding all segments and saving them as Look-Up-Tables (LUTs) 04_find_segments_full.py  &gt; **WARNING**  &gt; This cannot be run if `03_agglomerate_blockwise.py` has not been run.  &gt; **Don't forget to pass `daisy_logs/{filename}_fragments/config_0.yaml` from your daisy_logs folder auto-created under `catena/local_shape_descriptors`.**  &gt; Output LUTs are saved under `lsd_outputs`   Create a LUT file    Note: `hist_quant_50` must exist in the db as a collection. If not, check your config file to find at what is the starting value of `_C.INS_SEGMENT.THRESHOLDS`, that is your `hist_quant_{value_in_decimals * 100}`. Example: for `_C.INS_SEGMENT.THRESHOLDS = np.arange(0.35, 0.80, 0.05).tolist()`, you should pass `-mf hist_quant_35`.  <pre><code>python 04_find_segments_full.py -c daisy_logs/{filename}_fragments/config_0.yaml -mf hist_quant_50 -th 0.7\n</code></pre>  Extracting a final segmentation 05_extract_segmentation_from_lut.py  &gt; **WARNING**  &gt; This cannot be run if `04_find_segments_full.py` has not been run.  &gt; **Don't forget to pass `daisy_logs/{filename}_pred_affs/config_0.yaml` from your daisy_logs folder auto-created under `catena/local_shape_descriptors`.**  &gt; Final segmentations are saved in the zarr under `lsd_outputs`.   Extract Segments from LUT    Note: `hist_quant_50` must exist in the db as a collection. If not, check your config file to find at what is the starting value of `_C.INS_SEGMENT.THRESHOLDS`, that is your `hist_quant_{value_in_decimals * 100}`. Example: for `_C.INS_SEGMENT.THRESHOLDS = np.arange(0.35, 0.80, 0.05).tolist()`, you should pass `-mf hist_quant_35`. <pre><code>python 05_extract_segmentation_from_lut.py -c daisy_logs/{filename}_fragments/config_0.yaml -mf hist_quant_50 -th 0.7\n</code></pre> <p>NOTE Small Rois can be proofread with Napari-based Seg2Link.</p>"},{"location":"modules/local-shape-descriptors/#performance-of-lsds-on-held-out-in-distribution-and-out-of-distribution-datasets","title":"Performance of LSDs on held-out (in-distribution) and out-of-distribution datasets","text":"<ol> <li>Performance on Octo (unseen data): A Multi-task (MT) LSD model trained solely on Hemibrain (resolution: <code>8nm^3</code>, FIBSEM; <code>~40</code> microns) dataset on Octo (resolution: <code>8nm^3</code>, FIBSEM; <code>20 x 200 x 200</code> Roi in zyx) achieves <code>~0.05</code> Adapted Rand Error for a segmentation for agglomeration thresholds <code>50%-60%</code>.</li> </ol> <ul> <li>3D Neuroglancer Snapshot of Selected Segmentations</li> </ul>"},{"location":"modules/local-shape-descriptors/design-choices/","title":"Design Choices","text":"<p>This page explains the decisions we made, alternatives considered, trade-offs, and future work.</p>"},{"location":"modules/local-shape-descriptors/design-choices/#problem-goal","title":"Problem / Goal","text":"<p>What outcome are we optimizing for?</p>"},{"location":"modules/local-shape-descriptors/design-choices/#alternatives-considered","title":"Alternatives Considered","text":"<ul> <li>Option A \u2013 pros/cons</li> <li>Option B \u2013 pros/cons</li> <li>Option C \u2013 pros/cons</li> </ul>"},{"location":"modules/local-shape-descriptors/design-choices/#decision","title":"Decision","text":"<p>What we chose and why.</p>"},{"location":"modules/local-shape-descriptors/design-choices/#trade-offs","title":"Trade-offs","text":"<p>Compute, memory, DX, accuracy, portability, etc.</p>"},{"location":"modules/local-shape-descriptors/design-choices/#implementation-notes","title":"Implementation Notes","text":"<p>Key parameters, scripts, data flow.</p>"},{"location":"modules/local-shape-descriptors/design-choices/#operational-guidance","title":"Operational Guidance","text":"<p>Tuning tips, failure modes, troubleshooting.</p>"},{"location":"modules/local-shape-descriptors/design-choices/#future-work-open-questions","title":"Future Work / Open Questions","text":"<p>What we plan to revisit and why.</p>"},{"location":"modules/mitochondria-segmentation/","title":"Mitochondria Segmentation","text":"<p>Short overview of what this module does and links to usage.</p> <ul> <li>Install &amp; Usage: See the module's README and scripts.</li> <li>Design Choices: See Design Choices for the \"why\" behind the \"what\".</li> </ul>"},{"location":"modules/mitochondria-segmentation/design-choices/","title":"Design Choices","text":"<p>This page explains the decisions we made, alternatives considered, trade-offs, and future work.</p>"},{"location":"modules/mitochondria-segmentation/design-choices/#problem-goal","title":"Problem / Goal","text":"<p>What outcome are we optimizing for?</p>"},{"location":"modules/mitochondria-segmentation/design-choices/#alternatives-considered","title":"Alternatives Considered","text":"<ul> <li>Option A \u2013 pros/cons</li> <li>Option B \u2013 pros/cons</li> <li>Option C \u2013 pros/cons</li> </ul>"},{"location":"modules/mitochondria-segmentation/design-choices/#decision","title":"Decision","text":"<p>What we chose and why.</p>"},{"location":"modules/mitochondria-segmentation/design-choices/#trade-offs","title":"Trade-offs","text":"<p>Compute, memory, DX, accuracy, portability, etc.</p>"},{"location":"modules/mitochondria-segmentation/design-choices/#implementation-notes","title":"Implementation Notes","text":"<p>Key parameters, scripts, data flow.</p>"},{"location":"modules/mitochondria-segmentation/design-choices/#operational-guidance","title":"Operational Guidance","text":"<p>Tuning tips, failure modes, troubleshooting.</p>"},{"location":"modules/mitochondria-segmentation/design-choices/#future-work-open-questions","title":"Future Work / Open Questions","text":"<p>What we plan to revisit and why.</p>"},{"location":"modules/neurotransmitter-classification/","title":"Neurotransmitter Classification","text":"<p>Short overview of what this module does and links to usage.</p> <ul> <li>Install &amp; Usage: See the module's README and scripts.</li> <li>Design Choices: See Design Choices for the \"why\" behind the \"what\".</li> </ul>"},{"location":"modules/neurotransmitter-classification/design-choices/","title":"Design Choices","text":"<p>This page explains the decisions we made, alternatives considered, trade-offs, and future work.</p>"},{"location":"modules/neurotransmitter-classification/design-choices/#problem-goal","title":"Problem / Goal","text":"<p>What outcome are we optimizing for?</p>"},{"location":"modules/neurotransmitter-classification/design-choices/#alternatives-considered","title":"Alternatives Considered","text":"<ul> <li>Option A \u2013 pros/cons</li> <li>Option B \u2013 pros/cons</li> <li>Option C \u2013 pros/cons</li> </ul>"},{"location":"modules/neurotransmitter-classification/design-choices/#decision","title":"Decision","text":"<p>What we chose and why.</p>"},{"location":"modules/neurotransmitter-classification/design-choices/#trade-offs","title":"Trade-offs","text":"<p>Compute, memory, DX, accuracy, portability, etc.</p>"},{"location":"modules/neurotransmitter-classification/design-choices/#implementation-notes","title":"Implementation Notes","text":"<p>Key parameters, scripts, data flow.</p>"},{"location":"modules/neurotransmitter-classification/design-choices/#operational-guidance","title":"Operational Guidance","text":"<p>Tuning tips, failure modes, troubleshooting.</p>"},{"location":"modules/neurotransmitter-classification/design-choices/#future-work-open-questions","title":"Future Work / Open Questions","text":"<p>What we plan to revisit and why.</p>"},{"location":"modules/proofreading/","title":"Proofreading","text":"<p>Short overview of what this module does and links to usage.</p> <ul> <li>Install &amp; Usage: See the module's README and scripts.</li> <li>Design Choices: See Design Choices for the \"why\" behind the \"what\".</li> </ul>"},{"location":"modules/proofreading/design-choices/","title":"Design Choices","text":"<p>This page explains the decisions we made, alternatives considered, trade-offs, and future work.</p>"},{"location":"modules/proofreading/design-choices/#problem-goal","title":"Problem / Goal","text":"<p>What outcome are we optimizing for?</p>"},{"location":"modules/proofreading/design-choices/#alternatives-considered","title":"Alternatives Considered","text":"<ul> <li>Option A \u2013 pros/cons</li> <li>Option B \u2013 pros/cons</li> <li>Option C \u2013 pros/cons</li> </ul>"},{"location":"modules/proofreading/design-choices/#decision","title":"Decision","text":"<p>What we chose and why.</p>"},{"location":"modules/proofreading/design-choices/#trade-offs","title":"Trade-offs","text":"<p>Compute, memory, DX, accuracy, portability, etc.</p>"},{"location":"modules/proofreading/design-choices/#implementation-notes","title":"Implementation Notes","text":"<p>Key parameters, scripts, data flow.</p>"},{"location":"modules/proofreading/design-choices/#operational-guidance","title":"Operational Guidance","text":"<p>Tuning tips, failure modes, troubleshooting.</p>"},{"location":"modules/proofreading/design-choices/#future-work-open-questions","title":"Future Work / Open Questions","text":"<p>What we plan to revisit and why.</p>"},{"location":"modules/simpsyn/","title":"Synful","text":"<p>Short overview of what this module does and links to usage.</p> <ul> <li>Install &amp; Usage: See the module's README and scripts.</li> <li>Design Choices: See Design Choices for the \"why\" behind the \"what\".</li> </ul>"},{"location":"modules/simpsyn/design-choices/","title":"Design Choices","text":"<p>This page explains the decisions we made, alternatives considered, trade-offs, and future work.</p>"},{"location":"modules/simpsyn/design-choices/#problem-goal","title":"Problem / Goal","text":"<p>What outcome are we optimizing for?</p>"},{"location":"modules/simpsyn/design-choices/#alternatives-considered","title":"Alternatives Considered","text":"<ul> <li>Option A \u2013 pros/cons</li> <li>Option B \u2013 pros/cons</li> <li>Option C \u2013 pros/cons</li> </ul>"},{"location":"modules/simpsyn/design-choices/#decision","title":"Decision","text":"<p>What we chose and why.</p>"},{"location":"modules/simpsyn/design-choices/#trade-offs","title":"Trade-offs","text":"<p>Compute, memory, DX, accuracy, portability, etc.</p>"},{"location":"modules/simpsyn/design-choices/#implementation-notes","title":"Implementation Notes","text":"<p>Key parameters, scripts, data flow.</p>"},{"location":"modules/simpsyn/design-choices/#operational-guidance","title":"Operational Guidance","text":"<p>Tuning tips, failure modes, troubleshooting.</p>"},{"location":"modules/simpsyn/design-choices/#future-work-open-questions","title":"Future Work / Open Questions","text":"<p>What we plan to revisit and why.</p>"},{"location":"modules/synful/","title":"Synful","text":"<p>Short overview of what this module does and links to usage.</p> <ul> <li>Install &amp; Usage: See the module's README and scripts.</li> <li>Design Choices: See Design Choices for the \"why\" behind the \"what\".</li> </ul>"},{"location":"modules/synful/design-choices/","title":"Design Choices","text":"<p>This page explains the decisions we made, alternatives considered, trade-offs, and future work.</p>"},{"location":"modules/synful/design-choices/#problem-goal","title":"Problem / Goal","text":"<p>What outcome are we optimizing for?</p>"},{"location":"modules/synful/design-choices/#alternatives-considered","title":"Alternatives Considered","text":"<ul> <li>Option A \u2013 pros/cons</li> <li>Option B \u2013 pros/cons</li> <li>Option C \u2013 pros/cons</li> </ul>"},{"location":"modules/synful/design-choices/#decision","title":"Decision","text":"<p>What we chose and why.</p>"},{"location":"modules/synful/design-choices/#trade-offs","title":"Trade-offs","text":"<p>Compute, memory, DX, accuracy, portability, etc.</p>"},{"location":"modules/synful/design-choices/#implementation-notes","title":"Implementation Notes","text":"<p>Key parameters, scripts, data flow.</p>"},{"location":"modules/synful/design-choices/#operational-guidance","title":"Operational Guidance","text":"<p>Tuning tips, failure modes, troubleshooting.</p>"},{"location":"modules/synful/design-choices/#future-work-open-questions","title":"Future Work / Open Questions","text":"<p>What we plan to revisit and why.</p>"},{"location":"modules/visualize/","title":"Visualize","text":"<p>Short overview of what this module does and links to usage.</p> <ul> <li>Install &amp; Usage: See the module's README and scripts.</li> <li>Design Choices: See Design Choices for the \"why\" behind the \"what\".</li> </ul>"},{"location":"modules/visualize/design-choices/","title":"Design Choices","text":"<p>This page explains the decisions we made, alternatives considered, trade-offs, and future work.</p>"},{"location":"modules/visualize/design-choices/#problem-goal","title":"Problem / Goal","text":"<p>What outcome are we optimizing for?</p>"},{"location":"modules/visualize/design-choices/#alternatives-considered","title":"Alternatives Considered","text":"<ul> <li>Option A \u2013 pros/cons</li> <li>Option B \u2013 pros/cons</li> <li>Option C \u2013 pros/cons</li> </ul>"},{"location":"modules/visualize/design-choices/#decision","title":"Decision","text":"<p>What we chose and why.</p>"},{"location":"modules/visualize/design-choices/#trade-offs","title":"Trade-offs","text":"<p>Compute, memory, DX, accuracy, portability, etc.</p>"},{"location":"modules/visualize/design-choices/#implementation-notes","title":"Implementation Notes","text":"<p>Key parameters, scripts, data flow.</p>"},{"location":"modules/visualize/design-choices/#operational-guidance","title":"Operational Guidance","text":"<p>Tuning tips, failure modes, troubleshooting.</p>"},{"location":"modules/visualize/design-choices/#future-work-open-questions","title":"Future Work / Open Questions","text":"<p>What we plan to revisit and why.</p>"}]}